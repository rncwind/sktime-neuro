{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import *\n",
    "from sktime_neuro.datasets.matching_pennies_util import *\n",
    "from sktime_neuro.transformations.multivariate_detrender import ColumnDetrender\n",
    "from sktime_neuro.transformations.preprocessing.PREP import do_prep, build_prep_params\n",
    "from sktime_neuro.transformations.series_to_panel.eeg_epoching import epoch\n",
    "from sktime_neuro.utils.mne_processing import create_annotation\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime_neuro.datasets.matching_pennies_util import PENNIES_ONSET_LABELS, load_pickles\n",
    "from sktime_neuro.transformations.series.filterforseries import FilterforSeries\n",
    "from sklearn.metrics import *\n",
    "from mne.epochs import Epochs\n",
    "from typing import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def detrend(data, n_jobs=1) -> np.ndarray:\n",
    "    dt = ColumnDetrender(data)\n",
    "    return dt.detrend(n_jobs=n_jobs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def load_subject_and_detrend(subjectId: int) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    raw = get_raw(subjectId)\n",
    "    sf = raw.info[\"sfreq\"]\n",
    "    annotations = create_annotation(raw)\n",
    "    data = raw.get_data().transpose()\n",
    "    detrended = detrend(data, -1)\n",
    "    return annotations, detrended, sf\n",
    "\n",
    "def load_subject(sid):\n",
    "    raw = get_raw(sid)\n",
    "    sf = raw.info[\"sfreq\"]\n",
    "    annotations = create_annotation(raw)\n",
    "    data = raw.get_data().transpose()\n",
    "    return annotations, data, sf\n",
    "\n",
    "def load_subject_detrend_filter(subjectId: int, lf: float, hf: float, resampleTo = None) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    raw = get_raw(subjectId)\n",
    "    sf = raw.info[\"sfreq\"]\n",
    "    annotations = create_annotation(raw)\n",
    "    data = raw.get_data().transpose()\n",
    "    detrended = detrend(data, -1)\n",
    "    if resampleTo is None:\n",
    "        resampleTo = sf\n",
    "    if resampleTo is not None:\n",
    "        sf = resampleTo\n",
    "    #filtered = FilterforSeries(lf, hf, resampleTo).fit_transform(detrended)\n",
    "    filtered = applyfilter(detrended, lf, hf, resampleTo)\n",
    "    return annotations, filtered, sf\n",
    "\n",
    "def load_all_subjects_raw() -> List[Tuple[np.ndarray, np.ndarray, float]]:\n",
    "    allData = []\n",
    "    for i in range(5,12):\n",
    "        allData.append(load_subject_and_detrend(i))\n",
    "    return allData\n",
    "\n",
    "def load_all_subjects_filter(lf: float, hf: float, rsto = None) -> List[Tuple[np.ndarray, np.ndarray, float]]:\n",
    "    allData = []\n",
    "    for i in range(5,12):\n",
    "        allData.append(load_subject_detrend_filter(i, lf, hf, rsto))\n",
    "    return allData\n",
    "\n",
    "def applyfilter(detrended, lf, hf, sf, rsto):\n",
    "    if rsto is None:\n",
    "        rsto = sf\n",
    "    filtered = FilterforSeries(l_freq=lf, h_freq=hf, sfreq=rsto).fit_transform(detrended)\n",
    "    return filtered"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def epoch_subject(subjectData: Tuple[np.ndarray, np.ndarray, float]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    epochs, annotations = epoch(subjectData[1], subjectData[0], PENNIES_ONSET_LABELS, [-0.5, 0.5], sfreq=subjectData[2])\n",
    "    return epochs, annotations\n",
    "\n",
    "def epoch_set(dataset: List[Tuple[np.ndarray, np.ndarray, float]]) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    epoched = []\n",
    "    for subj in dataset:\n",
    "        epoched.append(epoch_subject(subj))\n",
    "    return epoched"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patchouli/programming/foss/sktime-neuro/sktime_neuro/datasets/matching_pennies_util.py:16: RuntimeWarning: Did not find any eeg.json associated with sub-08_task-matchingpennies.\n",
      "\n",
      "The search_str was \"/home/patchouli/programming/foss/sktime-neuro/cache/eeg_matchingpennies/sub-08/**/eeg/sub-08*eeg.json\"\n",
      "  return read_raw_bids(bids_path=bidspath, verbose=False)\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Uncomment this if you don't have them pickled already\n",
    "#allData = load_all_subjects()\n",
    "allData = load_pickles(\"detrended\")\n",
    "#i = 0\n",
    "#for d in allData:\n",
    "    #filtered = applyfilter(d[1], 0.5, 50, d[2], None)\n",
    "    #allData[i][1] = filtered\n",
    "    #allData[i] = (allData[i][0], filtered, allData[i][2])\n",
    "    #i = i+1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "epochedSet = epoch_set(allData)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform a test_train_split and classify on the first subject's data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build a train set. [0][0] for the data, [0][1] for labels\n",
    "# This creates a 225/75 split of /epochs/\n",
    "x_train, x_test, y_train, y_test = train_test_split(epochedSet[0][0], epochedSet[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rocket = RocketClassifier(n_jobs=16)\n",
    "rocket.fit(x_train, y_train)\n",
    "pred = rocket.predict(x_test)\n",
    "print(classification_report(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run a 5-fold crossvalidation on every dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scorevec = []\n",
    "for i in range(0,len(epochedSet)):\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(epochedSet[i][0], epochedSet[i][1])\n",
    "    scores = cross_val_score(rocket, epochedSet[i][0], epochedSet[i][1], cv=5)\n",
    "    scorevec.append(scores)\n",
    "    print(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.savetxt(\"latestresults.csv\", scorevec, delimiter=', ', fmt='%12.8f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}